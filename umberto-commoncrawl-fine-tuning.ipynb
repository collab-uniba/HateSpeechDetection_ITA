{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!gdown --id 1oWqGyirJe85zUnrwX3BUxKUTQpxzXCEJ -O Training e test set Umberto.zip\n\nimport os\nos.mkdir('/content/Training e test set Umberto')\n!unzip /content/Training e test set Umberto.zip -d /content/Training e test set Umberto/\n","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:42.20794Z","iopub.execute_input":"2021-11-11T11:48:42.208353Z","iopub.status.idle":"2021-11-11T11:48:42.231925Z","shell.execute_reply.started":"2021-11-11T11:48:42.208245Z","shell.execute_reply":"2021-11-11T11:48:42.231132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pathlib\nimport torch\nimport pandas as pd\nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\";\n\nMODEL_NAME=\"Musixmatch/umberto-commoncrawl-cased-v1\"","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:42.233635Z","iopub.execute_input":"2021-11-11T11:48:42.233988Z","iopub.status.idle":"2021-11-11T11:48:43.517154Z","shell.execute_reply.started":"2021-11-11T11:48:42.233951Z","shell.execute_reply":"2021-11-11T11:48:43.516417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path= \"../input/dati-di-training-e-di-test/haspeede2_dev_taskAB.csv\"\ntest_path=\"../input/dati-di-training-e-di-test/haspeede2_reference_taskAB-tweets.csv\"\ntr_path=pathlib.Path(train_path)\nte_path=pathlib.Path(test_path)\nif tr_path.exists():\n    print(\"Train data path set.\")\nelse:\n    raise SystemExit(\"Training Data Path does not exist.\")\n\nif te_path.exists():\n    print(\"Test data path set.\")\nelse:\n    raise SystemExit(\"Test Data Path does not exist.\")","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:43.520104Z","iopub.execute_input":"2021-11-11T11:48:43.520332Z","iopub.status.idle":"2021-11-11T11:48:43.532885Z","shell.execute_reply.started":"2021-11-11T11:48:43.520299Z","shell.execute_reply":"2021-11-11T11:48:43.532162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df= pd.read_csv(train_path, encoding='utf-8', sep=\"\\t\", header=None)\ntrain_df=train_df.drop([0])\ntrain_df.head()\n\ntest_df= pd.read_csv(test_path, encoding='utf-8', sep=\"\\t\",header=None)\ntest_df.head()\nfrom datasets import Dataset\n\nfrom sklearn import preprocessing\n\ntrain_df[2] = [int(x) for x in train_df[2]]\n\ntrain=Dataset.from_pandas(train_df)\ntest=Dataset.from_pandas(test_df)\n\n\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"1\"], padding=\"max_length\",max_length=100, truncation=True)\n\ntokenized_train = train.map(tokenize_function, batched=True)\ntokenized_test= test.map(tokenize_function, batched=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:43.534878Z","iopub.execute_input":"2021-11-11T11:48:43.535288Z","iopub.status.idle":"2021-11-11T11:48:46.241357Z","shell.execute_reply.started":"2021-11-11T11:48:43.535251Z","shell.execute_reply":"2021-11-11T11:48:46.239914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntokenized_train = tokenized_train.remove_columns([\"0\"])\ntokenized_train = tokenized_train.remove_columns([\"1\"])\ntokenized_train = tokenized_train.remove_columns([\"3\"])\ntokenized_train = tokenized_train.remove_columns([\"__index_level_0__\"])\ntokenized_train = tokenized_train.rename_column(\"2\", \"labels\")\ntokenized_train.set_format(\"torch\")\ntokenized_test = tokenized_test.remove_columns([\"0\"])\ntokenized_test = tokenized_test.remove_columns([\"1\"])\ntokenized_test = tokenized_test.remove_columns([\"3\"])\ntokenized_test = tokenized_test.rename_column(\"2\", \"labels\")\ntokenized_test.set_format(\"torch\")\n","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:46.242561Z","iopub.status.idle":"2021-11-11T11:48:46.243131Z","shell.execute_reply.started":"2021-11-11T11:48:46.242877Z","shell.execute_reply":"2021-11-11T11:48:46.242902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(tokenized_train,batch_size=32)\neval_dataloader = DataLoader(tokenized_test, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:46.244325Z","iopub.status.idle":"2021-11-11T11:48:46.244886Z","shell.execute_reply.started":"2021-11-11T11:48:46.244649Z","shell.execute_reply":"2021-11-11T11:48:46.244676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:46.24594Z","iopub.status.idle":"2021-11-11T11:48:46.246514Z","shell.execute_reply.started":"2021-11-11T11:48:46.246275Z","shell.execute_reply":"2021-11-11T11:48:46.246302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=2e-4)","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:46.247565Z","iopub.status.idle":"2021-11-11T11:48:46.248132Z","shell.execute_reply.started":"2021-11-11T11:48:46.247877Z","shell.execute_reply":"2021-11-11T11:48:46.247903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom transformers import get_scheduler\nfrom datasets import load_metric\n\nnum_epochs = 10\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps\n)\n\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)\n\n\nfrom tqdm.auto import tqdm\n\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\n\n\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        batch = {k: v for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\nmetric= load_metric(\"accuracy\")\nmodel.eval()\nfor batch in eval_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-11T11:48:46.249245Z","iopub.status.idle":"2021-11-11T11:48:46.249781Z","shell.execute_reply.started":"2021-11-11T11:48:46.249548Z","shell.execute_reply":"2021-11-11T11:48:46.249575Z"},"trusted":true},"execution_count":null,"outputs":[]}]}